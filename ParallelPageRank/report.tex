

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% REMOVE DRAFT MODE ([draft]) TO RENDER FULL DOCUMENT %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[draft]{report}





\usepackage{graphicx}
\usepackage{siunitx}
\sisetup{
  round-mode = places,
  round-precision = 3
}

% Insert a results file
\newcommand{\results}[1]{{\ttfamily \begin{longtabu}{rll}
                           \input{#1}
                         \end{longtabu}\clearpage}}
% format a result
\newcommand{\runsummary}[3]{}
\newcommand{\result}[3]{#1 & #2 & #3\\}

% name
\newcommand{\pagerank}{PageRank }
\newcommand{\pageranks}{PageRanks }
\lstset{}
\lstset{%
  escapeinside={(*}{*)},%
  language=bash
}

\title{CPE419 and CPE466 Joint Project\\Parallel Page Rank}
\author{
  Gilbert, Andrew\\
  \texttt{apgilber@calpoly.edu}
  \and
  Miller, Drew\\
  \texttt{dmille26@calpoly.edu}
  \and
  Terrell, Josh\\
  \texttt{jmterrel@calpoly.edu}
  \and
  Yost, Morgan\\
  \texttt{yost@calpoly.edu}
}
\date{}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

\section{Implementation Overview}
The previous implementation of pagerank represented the graph in structs and used threads to parallelize computation. To further increase performance, we vectorized the pagerank computation and used matrix math libraries for the Xeon Phi and GPU implementations.

\subsection{The non-zero transition probability problem}
A problem with vectorizing the pagerank algorithm is that without any memory optimizations, an $N\times N$ (where $N$ is node count) matrix must be created to represent the \textit{transition probability matrix}, $P$. There is a non-zero probability of transitioning from any node to any other node, so $P$ is throughly dense. For the \textit{live journal} dataset, we simply could not represent a $4\text{M} \times 4\text{M}$ matrix in memory, so we got creative.

The equation for the original transition probability matrix is \vref{dense_p}, where $P_{ij}$ is the value of the row $i$ and column $j$ representing the probability of transitioning from node $i$ to node $j$.


\begin{equation}
\label{dense_p}
P_{ij} = 
\begin{cases}
  \frac{1-d}{N} + \frac{d}{\operatorname{outdegree}(i)} & \text{if $i\rightarrow j$ is an edge}\\
  \frac{1-d}{N}                                          & \text{if $i\rightarrow j$ is not an edge}\\
  \frac{1}{N}                                            & \text{if $i$ is a sink node}
\end{cases}
\end{equation}


In order to represent the matrix as a sparse matrix, we subtracted $\frac{1-d}{N}$ from every cell in the matrix to set one of the above cases to zero. We also set each row to zero if it was a sink node so that the definition of $P$ changed to \vref{sparse_p}

\begin{equation}
\label{sparse_p}
P_{ij} = 
\begin{cases}
\frac{d}{\operatorname{outdegree}(i)}                   & \text{if $i\rightarrow j$ is an edge}\\
0                                                        & \text{otherwise}
\end{cases}
\end{equation}

The problem with modifying $P$ like this is that $P$ has a completely different value than it should. Multiplying $\Pi^T P$ no longer yields the next $\Pi$ for the iteration. When making these modifications, we had to adjust the equation for the iteration from \vref{basic_iter} to \vref{combine_iter}

\begin{equation}
\label{basic_iter}
  \Pi = P^T \Pi
\end{equation}

\begin{equation}
\label{combine_iter}
  \Pi = P^T \Pi + \frac{1-d}{N\cdot \Sigma \Pi} + \frac{d}{N \cdot \Pi^T S}
\end{equation}

where $S$ is a vector such that \vref{s_cond} holds.

\begin{equation}
\label{s_cond}
  \begin{cases}
    S_i = 1 & \text{if row $i$ of $P$ is a sink node}\\
    S_i = 0 & \text{otherwise}
  \end{cases}
\end{equation}

Not only did this solve the problem of representing a $N\times N$ matrix, but by reducing the matrix to $E$ (where $E$ is edge count) cells of a sparse matrix, we accidently, conviniently, and significantly reduced the number of operations to be computed on every iteration, assuming nodes have far fewer out edges than the number of nodes on the graph.

\subsection{Memory movement}
In our previous implementation, we parsed the datasets in python and used cffi to pass data to c to construct the graph. We optimized the load significantly by performing all the dataset reading in c. Our program performs a mmap of the file into memory then, rather than splitting the file into many substrings, we use c string traversal to construct the graph. This results in much less writing to memory and no allocation after the parsing has begun.

TODO memory to and from GPU

\section{Results}
\subsection{NCAA Football}
This dataset must be converted to the snap format using \texttt{reformat.py} as described in the README (Appendix A).
\subsection{State Borders}
This dataset must be converted to the snap format using \texttt{reformat.py} as described in the README (Appendix A).
\subsection{Karate}
This dataset must be converted to the snap format using \texttt{reformat.py} as described in the README (Appendix A).
\subsection{Dolphins}
This dataset must be converted to the snap format using \texttt{reformat.py} as described in the README (Appendix A).
\subsection{Les Miserables}
This dataset must be converted to the snap format using \texttt{reformat.py} as described in the README (Appendix A).
\subsection{Political Blogs}
This dataset must be converted to the snap format using \texttt{reformat.py} as described in the README (Appendix A).
\subsection{Wiki Vote}
\subsection{p2p-Gnutella05}
\subsection{SlashdotZoo}
\subsection{Amazon}
\subsection{LiveJournal}

\section{Performance Summary}

\appendix

\section{README}

\subsection{Dataset Format}
The ranker scripts assume the graph is directed in the following form.

\begin{lstlisting}
# a comment
# a comment
# Nodes: <node count> Edges: <edge count>
# a comment
node_from<tab>node_to
node_from<tab>node_to
node_from<tab>node_to
\end{lstlisting}

All datasets not in the above format must be converted to this format using the conversion script \texttt{reformat.py}.

To convert a dataset, run
\begin{lstlisting}
python3 reformat.py source_file.csv > output_filename.txt
\end{lstlisting}

This will create a file compatible with the C code, along with a Python pickle named source_file.csv.pickle which contains mappings from the node numbers in the new file to the node names in the old file, along with the file load time in the Python code.

Next, run the ranker script as described below, then convert the
results back to the named-node format with
\begin{lstlisting}
python3 unformat.py source_file.csv.pickle < ranker_results.txt > results.txt
\end{lstlisting}

\subsection{Compile}
\begin{lstlisting}
cd src
make
\end{lstlisting}

\subsection{Compute Page Rank}
\begin{lstlisting}
cd src
./pageRank <path/to/snap-formatted-dataset.csv>
\end{lstlisting}
\end{document}
